---
title: "QDA_KNN_NB"
author: "Jianghui Lin"
date: "5/15/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # data manipulation
library(corrplot) # correlation plot
library(caret) # model training
library(MASS)
library(caret)
library(glmnet)
library(e1071)
library(mlbench)
library(pROC)
library(AppliedPredictiveModeling)
library(ISLR)
```

```{r}
test_df<-read.csv("test.csv")
train_df<-read.csv("train.csv")
```

#QDA
```{r}
set.seed(1)
qda.fit <- qda(diagnosis~.,
               data = train_df)
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE) 
model.qda <- train(x = train_df[,-1],
                   y = train_df$diagnosis,
                   method = "qda",
                   metric = "ROC",
                   trControl = ctrl)

qda.pred <- predict(qda.fit, newdata = test_df)
head(qda.pred$posterior)

roc.qda <- roc(test_df$diagnosis, qda.pred$posterior[,2], 
               levels = c("B","M"))

plot(roc.qda, legacy.axes = TRUE, print.auc = TRUE,main="QDA ROC Plot")
```
**AUC Value for QDA is 0.990 as shown above.**

#KNN
```{r}
set.seed(1)
model.knn <- train(x = train_df[,-1],
                   y = train_df$diagnosis,
                   method = "knn",
                   preProcess = c("center", "scale"), 
                   tuneGrid = data.frame(k = seq(1,50,by=1)),  
                   trControl = ctrl)
model.knn$bestTune
ggplot(model.knn)
pred_knn = predict.train(model.knn, newdata = test_df, type = 'prob')
roc_knn <- roc(test_df$diagnosis, pred_knn[,2],
               levels = c("B", "M"))
plot.roc(roc_knn, legacy.axes = TRUE, print.auc = TRUE,main="KNN ROC Plot")
```
**AUC Value for KNN is 0.989 as shown above.**

#Bayes
```{r,warning=F}
set.seed(1)

nbGrid <- expand.grid(usekernel = c(FALSE,TRUE),
                      fL = 1, 
                      adjust = seq(0,5,by = 1))

model.nb <- train(x = train_df[,-1],
                  y = train_df$diagnosis,
                  method = "nb",
                  tuneGrid = nbGrid,
                  metric = "ROC",
                  trControl = ctrl)

plot(model.nb)
```

#Compare QDA, NB and KNN   
```{r}
res <- resamples(list(QDA=model.qda,NB = model.nb, KNN = model.knn))
summary(res)
```

Now let's look at the test set performance.
```{r, warning=FALSE}
library(stats)
pred_knn = predict.train(model.knn, newdata = test_df, type = 'prob')[,2]
pred_qda = predict.train(model.qda, newdata = test_df, type = 'prob')[,2]
pred_nb = predict.train(model.nb, newdata = test_df, type = 'prob')[,2]

roc.nb <- roc(test_df$diagnosis, pred_nb)
roc.qda <- roc(test_df$diagnosis, pred_qda)
roc.knn <- roc(test_df$diagnosis, pred_knn)

auc <- c(roc.qda$auc[1], roc.nb$auc[1], roc.knn$auc[1])


plot(roc.qda, col = 1,legacy.axes=TRUE)
plot(roc.nb, col = 2,add=TRUE)
plot(roc.knn, col = 3,add=TRUE)
modelNames <- c("qda","nb","knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```
