---
title: "Linear_methods"
author: "Zixu Wang"
date: "May 16, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
library(corrplot) 
library(caret) 
library(glmnet)
library(MASS)
library(e1071)
library(mlbench)
library(pROC)
library(AppliedPredictiveModeling)
library(stats)
```

```{r}
test_df<-read.csv("test.csv")
train_df<-read.csv("train.csv")
```

### Produce some graphical summaries
```{r, cache=T}
featurePlot(x = train_df[, 2:31],
            y = train_df$diagnosis,
            scales = list(x=list(relation="free"),
            y=list(relation="free")),
            plot = "density", pch = "|",
            auto.key = list(columns = 2))
```

### Logistic Regression
```{r}
glm.fit <- glm(diagnosis~., data=train_df, family="binomial")
summary(glm.fit)

contrasts(train_df$diagnosis)

glm.pred.prob = predict(glm.fit, type = "response")
glm.pred = rep("B", length(glm.pred.prob))
glm.pred[glm.pred.prob > 0.5] = "M"
confusionMatrix(data = as.factor(glm.pred),
                reference = train_df$diagnosis,
                positive = "M")

glm.pred.prob.test = predict(glm.fit, type = "response", newdata = test_df)
roc.glm.test = roc(test_df$diagnosis, glm.pred.prob.test)
plot(roc.glm.test, legacy.axes = TRUE, print.auc = TRUE)

ctrl <-trainControl(method ="repeatedcv",
                    repeats =5,
                    summaryFunction =twoClassSummary,
                    classProbs =TRUE)
set.seed(1)
model.glm <-train(x=train_df[,2:31],
                  y=train_df$diagnosis,
                  method ="glm",
                  metric ="ROC",
                  trControl =ctrl)
model.glm$results$ROC
```

### Regularized Logistic Regression
```{r}
ctrl <-trainControl(method ="repeatedcv",
                    repeats =5,
                    summaryFunction =twoClassSummary,
                    classProbs =TRUE)

glmnGrid <-expand.grid(.alpha =seq(0,1,length =6),
                       .lambda =exp(seq(-6,-2,length =20)))
set.seed(1)
model.glmn <-train(x=train_df[,2:31],
                   y=train_df$diagnosis,
                   method ="glmnet",
                   tuneGrid =glmnGrid,
                   metric ="ROC",
                   trControl =ctrl)
plot(model.glmn,xTrans =function(x)log(x))
model.glmn$results$ROC %>% max

```

### LDA
```{r}
lda.fit <-lda(diagnosis~.,data = train_df)
plot(lda.fit)

lda.pred.test = predict(lda.fit, newdata = test_df)
roc.lda = roc(test_df$diagnosis, lda.pred.test$posterior[,2],
              levels = c("B", "M"))
plot(roc.lda, legacy.axes = TRUE, print.auc = TRUE)

## caret
ctrl <-trainControl(method ="repeatedcv",
                    repeats =5,
                    summaryFunction =twoClassSummary,
                    classProbs =TRUE)
set.seed(1)
model.lda <-train(x=train_df[,2:31],
                  y=train_df$diagnosis,
                  method ="lda",
                  metric ="ROC",
                  trControl =ctrl)

model.lda$result$ROC
```

```{r}
pred_glm = predict.train(model.glm, newdata = test_df, type = 'prob')[,2]
pred_lda = predict.train(model.lda, newdata = test_df, type = 'prob')[,2]
pred_knn = predict.train(model.knn, newdata = test_df, type = 'prob')[,2]
pred_qda = predict.train(model.qda, newdata = test_df, type = 'prob')[,2]
pred_nb = predict.train(model.nb, newdata = test_df, type = 'prob')[,2]

roc.glm <- roc(test_df$diagnosis, pred_glm)
roc.lda <- roc(test_df$diagnosis, pred_lda)
roc.nb <- roc(test_df$diagnosis, pred_nb)
roc.qda <- roc(test_df$diagnosis, pred_qda)
roc.knn <- roc(test_df$diagnosis, pred_knn)

auc <- c(roc.glm$auc[1], roc.lda$auc[1], roc.qda$auc[1], roc.nb$auc[1], roc.knn$auc[1])

plot(roc.glm, col=1, legacy.axes=TRUE)
plot(roc.lda, col=2, add=TRUE)
plot(roc.qda, col = 3, add=TRUE)
plot(roc.nb, col = 4, add=TRUE)
plot(roc.knn, col = 5, add=TRUE)
modelNames <- c("glm","lda","qda","nb","knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```

```{r}
resamp <- resamples(list(glm.fit = model.glm,
                         glmn.fit = model.glmn,
                         lda.fit = model.lda,
                         qda.fit = model.qda,
                         knn.fit = model.knn,
                         bayes.fit = model.nb
                         ))
bwplot(resamp)
summary(resamp)
```

